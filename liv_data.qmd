---
title: "liv_data"
format: 
  html:
    self-contained: true
params:
  hide_answer: false
  show_complete_TOST: false
---

## Exploratory analysis of Liv's data

This report contains R code and output intermingled using 
[quarto](https://quarto.org), 
based on the Literate Programming paradigm of Knuth.

The input is a simplified version of Liv's .xlsx spreadsheets 
with extraneous material removed to make them easier to parse.

Load the necessary libraries and calculate the approximate density of each cushion.
Note that this is a guess as each cushion is made of both VF and HR, 
but we only have the weight of the combined cushion.

```{r}
#| echo: true
#| message: false
# Load required libraries.
library(dplyr)
library(TOSTER)
library(ggplot2)

# Set some printing options
options(digits = 3)        # Fewer significant figures because > 1Âµm is silly
options(row.names = FALSE) # don't want row numbers in tables
```

Read the recorded cushion dimensions and masses and calculate the density.
The `density_spec` table is from the Dunlop specification sheets and used to 
estimate the possible weight of the VF overlay, assuming it is within spec.

```{r}
#| echo: true
# Deal with density data separately as very different structure
# and needs several calculations to get the (approximate) density.

liv_density <- readxl::read_xlsx(here::here("data", "density.xlsx"),
                                 range = readxl::cell_cols("A:K"))
# Specification from Dunlop, in kg/m3
density_spec <- tibble::tribble(
  ~foam, ~min, ~max,
  "VF",       58.0, 62.0,
  "EN40-230", 39.0, 42.0,
  "EN50-250", 49.0, 53.5
)

# Calculate various volumes in mm3
liv_density <- liv_density %>%
  mutate(t_mean = rowMeans(across(starts_with("T"))),
         vf_vol = length * width * vf_thickness,
         sag_vol = (sag_height * sag_width * length), # cut-out for seat sag
         hr_vol = length * width * t_mean - vf_vol - sag_vol
        ) %>%
# The mass of VF is unknown, but can be estimated from the density_spec
  mutate(
    vf_min_mass = (vf_vol / 1E9) * filter(density_spec, foam == "VF")$max * 1000,
    vf_max_mass = (vf_vol / 1E9) * filter(density_spec, foam == "VF")$min * 1000,
    hr_max_mass = mass - vf_min_mass, # grams
    hr_min_mass = mass - vf_max_mass,
    hr_min = 1E6 * hr_min_mass / hr_vol,  # Convert back to kg/m3
    hr_max = 1E6 * hr_max_mass / hr_vol
  )

```

Now load the test results, rearrange them for easier automated processing and
calculate some summary statistics.

```{r}
# Read the testing results
data_file <- here::here("data", "results.xlsx")

# Display sheet names
sheet_names <- readxl::excel_sheets(data_file)
print(sheet_names)

# Read the two sheets constructed from Liv's data & name them
# Convert to long form for easier analysis,
# then combine both data sets by row and
# group by foam type, variable and the load level for each result
liv_data <- sheet_names %>%                  # Take the named sheets
  purrr::set_names() %>%                     # make them a named list
  purrr::map(                                # apply a function to each element
    function(x) {
      readxl::read_excel(data_file, x) %>%   # read the named sheet
      tidyr::pivot_longer(cols = where(is.numeric), # use the results columns
                   names_to = "level",       # column names to 'level'
                   values_to = "value"       # each value to 'value'
                  )
    }
  ) %>%
  bind_rows(.id = "var") %>%      # combine by rows, put original names in 'var'
  group_by(foam, var, level)      # make groups for each independent measurement

# liv_data is now a list with columns named
# var = lcdod or hysteresis
# cushion = cushion ID number
# foam = EN40-230 or EN50-250
# level = load level for measurement
# value = measurement


# Define a function to calculate the summary stats for each group.
# Return a data.frame to return multiple columns in one call.
# Original version used qnorm(), which gives the wrong numbers for small N
# and assumes is normal. Using qt() is more robust & accurate.
stats <- function(x, ci = 0.95) {
        mu <- mean(x)
        m <- median(x)
        sd <- sd(x)
        n <- length(x)
        se <- sd / sqrt(n)
        err <- qt((ci + 1)/2, df = n-1) * se
        
        data.frame(mean = mu, 
               median = m, 
               sd = sd, 
               se = se,
               n = n,
               upper = mu + err, 
               lower = mu - err
               )
    }

# Show the Summary stats for each variable,including the 95% CI
data_summary <- liv_data %>%
  summarise(stats(value, ci = 0.95)) %>%
  arrange(var, level, foam) # Re-order the output to be more readable

print(data_summary)
```

```{r}
# Make some simple box plots to show the spread of the data
plots <- list()
for (var_name in unique(liv_data$var)) {
  plots[[var_name]] <- liv_data %>%
    filter(var == var_name) %>%
    ggplot() +
    aes(y = value, x = foam, colour = foam) +
    geom_boxplot() +
    geom_jitter(colour = "black", width = 0.25) +
    labs(title = var_name, y = var_name) +
    facet_wrap(~level)
}
print(plots)
```

## TOST or equivalence testing

Run a **T**wo **O**ne **S**ided **T**est on each comparison group 
(i.e. compare foams for each measured variable and level)

```{r}
# Want to compare the different foams at each variable and level.
# Regroup the data with the required groups them map a function to each group
# This is a cleaner & better way to do the analysis, passing a formula to
# t_TOST, with data = .x, in the same way as is done with t.test()
# Previous code appears to have some bug, but was too hard to find in that mess.

regrouped <- liv_data %>% 
    ungroup() %>%        # remove the old groups first
    group_by(var, level) # then regroup by var & level

# Map the t_TOST function across each group
result_list <- regrouped %>%
    group_map(~ TOSTER::t_TOST(value ~ foam,   # compare value for each foam 
                               data = .x,      # .x is data for this group
                               paired = FALSE, 
                               eqb = mean(.x$value)/20 # +/- 5% of the mean
                               )
              )

# Get the group names & use to name the result list
names(result_list) <- regrouped %>%
  group_keys() %>%                   # get the keys from the grouping
  mutate(id = paste(var, level)) %>% # join the keys columns together
  pull(id)                           # extract the result column on it's own

```


```{r}
# This code has been cleaned up as well, using purrr::pwalk and just putting 
# the names in a second parallel list.
# Also made the headings between each test stand out a bit more 

# Define a function to print each results a bit nicer
# Prints some blank lines, the group name, padded to w characters with '='
# then the actual results
print_group <- function(group, content) {
  w <- 30
  separator <- strrep("=", w)
  wide_name <- stringr::str_pad(paste0(group, " "), # add a trailing space
                                width = w,
                                side = "right",
                                pad = "=")          # pad out to w chars wide
  # Use cat() for the header to get control over new lines etc.
  cat("\n\n",         
      separator, "\n",
      wide_name, "\n",
      separator, "\n"
      )
  # cat() can't handle complex objects, so use print()
  print(content)
}

# Get the group names & use to name the result list
result_names <- regrouped %>%
  group_keys() %>%                   # get the keys from the grouping
  mutate(id = paste(var, level)) %>% # join the keys columns together
  pull(id)                           # extract the result column on it's own

# Summary results
result_summary <- purrr::map(result_list, \(x) c(x$TOST$p.value)) %>% 
  bind_rows() %>% 
  t() %>% 
  as.data.frame() %>%  
  setNames(c("t.test", "eq_lower", "eq_upper")) %>% 
  tibble::rownames_to_column("experiment") %>% 
  tidyr::separate(col = experiment, into = c("variable", "level")) %>%
  mutate(different = ifelse(t.test < 0.05, "SIG", ""), 
         equivalent = ifelse((eq_lower < 0.05) & (eq_upper < 0.05), "SIG", ""))

print(result_summary)

if (params$show_complete_TOST) {
  # Print complete results
  purrr::pwalk(list(result_names, result_list), print_group)
}
```


`r if (params$hide_answer) "::: {.content-hidden}"`

## Possible Outlier or Anomalous Result

The hysteresis data look odd, and it looks like one point is an outlier.
Check which one by adding point labels to the plot

```{r}
# Add labels to the existing plot and redraw
plots[["hysteresis"]] %+% 
  geom_label(aes(label = cushion), 
             hjust = "left", alpha = 0.5, position = "dodge")

```



```{r}
# Notice an issue with one result - check if the density or mass is related
density_plot <- liv_data %>%
  filter(var == "hysteresis", foam == "EN40-230") |>
  left_join(liv_density, by = "cushion") |>
  ggplot() +
  aes(x=hr_max, y = value, colour = level, label = cushion) +
  geom_point() +
  geom_label(hjust = "left", alpha = 0.5, position = "dodge") +
  labs(title = "hysteresis vs density", 
         y = "hysteresis", 
         x = "max HR density")

print(density_plot)

```

Comparing the two plots it looks like `W855791-02` is anomalous.
Looking at the density & weight data, this cushion is much lighter than 
any other cushion (about 65 to 90 grams lighter).

```{r}
liv_density %>% 
  select(cushion, foam, mass, hr_min, hr_max) %>%
  print()

liv_density %>% 
  ggplot() + aes(y = cushion, x = mass, colour = foam) + geom_point()
```

There may be a problem with this cushion, and it should be checked.

If the density data *are* correct then the anomalous result is possibly due
to the different density of this cushion.

`r if (params$hide_answer) ":::"`
